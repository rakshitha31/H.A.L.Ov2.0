# -*- coding: utf-8 -*-
"""
Created on Sat May  4 11:12:15 2019

@author: K.S.LOHITH
"""


import cv2
import imutils
import numpy as np
from scipy import signal
from scipy.fftpack import fft
import numpy as np
from scipy.fftpack import fftfreq
import matplotlib.pyplot as plt

# Load the Haar cascades
face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
eyes_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')
blue = []
red = []
green = []
hue = []
saturation = []
value = []
redmean = 0
greenmean = 0
bluemean = 0
# Define function that will do detection
def detect(gray, frame):
  """ Input = greyscale image or frame from video stream
      Output = Image with rectangle box in the face
  """
  # Now get the tuples that detect the faces using above cascade
  faces = face_cascade.detectMultiScale(gray, 1.3, 5)
  # faces are the tuples of 4 numbers
  # x,y => upperleft corner coordinates of face
  # width(w) of rectangle in the face
  # height(h) of rectangle in the face
  # grey means the input image to the detector
  # 1.3 is the kernel size or size of image reduced when applying the detection
  # 5 is the number of neighbors after which we accept that is a face
  
  # Now iterate over the faces and detect eyes
  for (x,y,w,h) in faces:
    #cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,0), 2)
    # Arguements => image, top-left coordinates, bottomright coordinates, color, rectangle border thickness
    
    # we now need two region of interests(ROI) grey and color for eyes one to detect and another to draw rectangle
    roi_gray = gray[y:y+h, x:x+w]
    roi_color = frame[y:y+h, x:x+w]
    # Detect eyes now
    eyes = eyes_cascade.detectMultiScale(roi_gray, 1.1, 3)
    # Now draw rectangle over the eyes
    for (ex, ey, ew, eh) in eyes:
      #cv2.rectangle(roi_color, (ex,ey), (ex+ew, ey+eh), (0, 255, 0), 2)
      hx=ex
      hy=ey-30
      hw=ex+ew
      hh=ey+eh-30
        #cv2.rectangle(roi_color,(ex,ey-30),(ex+ew,ey+eh-30),(0,0,255),2)
    try:
        #cv2.rectangle(roi_color,(hx-15,hy-20),((2*hw)+45,hh-30),(0,0,255),2)
        roi = roi_color[hy-20:hh-30,hx-15:(2*hw)+45]
        cv2.imshow("roi",roi)
        b,g,r = cv2.split(roi)
        bl = np.mean(b)
        re = np.mean(r)
        gr = np.mean(g)
        blue.append(bl)
        red.append(re)
        green.append(gr)
        hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
        h, s, v = hsv[:, :, 0], hsv[:, :, 1], hsv[:, :, 2]
        hu = np.mean(h)
        sa = np.mean(s)
        va = np.mean(v)
        hue.append(hu)
        saturation.append(sa)
        value.append(va)
        # set blue and green channels to 0
        cv2.imshow("blue",b)
        cv2.imshow("red",r)
        cv2.imshow("green",g)
        return roi
    except UnboundLocalError:
        pass
    except:
        pass
  #return frame
def getmean():
    for i in range(len(blue)-1):
        blue[i] = abs(blue[i+1]-blue[i])
    for i in range(len(green)-1):
        green[i] = abs(green[i+1]-green[i])    
    for i in range(len(red)-1):
        red[i] = abs(red[i+1]-red[i])   
        
def getnormalized():
    redmean = sum(red)/len(red)
    greenmean = sum(green)/len(green)
    bluemean = sum(blue)/len(blue)
    for i in range(len(blue)):
        blue[i] = abs(blue[i]-bluemean)
    for i in range(len(green)):
        green[i] = abs(green[i]-greenmean)   
    for i in range(len(red)-1):
        red[i] = abs(red[i]-redmean)
        
def dofft():


    y1 = fft(red)
    y2 = fft(green)
    y3 = fft(blue)
    
    dred= signal.detrend(red)
    dgreen = signal.detrend(green)
    dblue = signal.detrend(blue)
    
    yd1 = fft(dred)
    yd2 = fft(dgreen)
    yd3 = fft(dblue)
    
    N = len(red)
    # sample spacing
    T = 1.0 / 100.0
    x = np.linspace(0.0, N*T, N)
    
    y1 = np.array(red)
    y2 = np.array(green)
    y3 = np.array(blue)
    
    yf1 = fft(y1)
    yf2 = fft(y2)
    yf3 = fft(y3)
    
    realyf1 = yf1.real
    realyf2 = yf2.real
    realyf3 = yf3.real
    
    yg1 = np.abs(yd1[:N//2])
    yg2 = np.abs(yd2[:N//2])
    yg3 = np.abs(yd3[:N//2])
    xf = np.linspace(0.0, 1.0/(2.0*T), N/2)
    #xf = xf[2:]
    xint = list(xf)
    #for i in xint:
    #    i = math.ceil(i)
    xf1 = xf*10
    
    
    
    fig, ax = plt.subplots()
    #ax.plot(xf*10, yg3)
    ax.plot(xf*10, yg2 , color="green")
    #ax.plot(xf*10, yg1)
    plt.show()
# Capture video from webcam 
video_capture = cv2.VideoCapture("rashi_new.mp4")
#video_capture.set(cv2.CV_CAP_PROP_FPS,60)
# Run the infinite loop
ret = True

while ret:
  try:
  # Read each frame
      ret, frame = video_capture.read()
      #print(frame.shape)
    #  if frame.empty():
    #      break;
      
      frame = cv2.resize(frame,(int(frame.shape[1]/2),int(frame.shape[0]/2)))
      frame = imutils.rotate_bound(frame,90)
      # Convert frame to grey because cascading only works with greyscale image
      gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
      # Call the detect function with grey image and colored frame
      canvas = detect(gray, frame)
      # Show the image in the screen
      #cv2.imshow("Video", canvas)
     # cv2.waitKey(1)
    #  if ret == False:
    #      break
     # Put the condition which triggers the end of program
    
    
      if cv2.waitKey(1) and 0xFF == ord('q'):
        break
  except AttributeError:
      break      
video_capture.release()
cv2.destroyAllWindows()
getmean()
#getnormalized()
dofft()

